{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386f299c",
   "metadata": {},
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5540e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability Mass Function (PMF):\n",
    "\n",
    "# PMF is used to describe the probability distribution of a discrete random variable. Discrete random variables are those that take on a countable number of distinct values, often whole numbers.\n",
    "# The PMF assigns probabilities to each possible outcome of the random variable.\n",
    "# Example:\n",
    "# Let's consider a simple example of rolling a fair six-sided die. The random variable X represents the outcome of the roll, and it can take on values from 1 to 6. The PMF for X is as follows:\n",
    "\n",
    "# P(X = 1) = 1/6\n",
    "# P(X = 2) = 1/6\n",
    "# P(X = 3) = 1/6\n",
    "# P(X = 4) = 1/6\n",
    "# P(X = 5) = 1/6\n",
    "# P(X = 6) = 1/6\n",
    "\n",
    "# In this case, the PMF specifies that each possible outcome has an equal probability of 1/6.\n",
    "\n",
    "# Probability Density Function (PDF):\n",
    "\n",
    "# PDF is used to describe the probability distribution of a continuous random variable. Continuous random variables can take on an infinite number of possible values within a certain range.\n",
    "# Instead of assigning probabilities to specific values, the PDF assigns probabilities to intervals or ranges of values. The area under the PDF curve within a specific interval represents the probability of the random variable falling within that interval.\n",
    "# Example:\n",
    "# Let's consider a continuous random variable Y that represents the height of people in a population, measured in inches. The PDF for Y might be a normal distribution curve (bell-shaped curve) with a mean of 68 inches and a standard deviation of 3 inches.\n",
    "\n",
    "# In this case, you cannot specify the probability of a person being exactly 70 inches tall because the number of possible heights is infinite. Instead, you can calculate probabilities related to intervals, such as finding the probability that a randomly selected person's height falls between 65 and 70 inches. This probability corresponds to the area under the PDF curve between 65 and 70 inches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67b142",
   "metadata": {},
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dbabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The Cumulative Distribution Function (CDF) is a mathematical concept used in probability and statistics to describe the cumulative probability distribution of a random variable. It provides information about the probability that a random variable takes on a value less than or equal to a specific value. CDF is used for both discrete and continuous random variables.\n",
    "\n",
    "# Mathematically, the CDF of a random variable X, denoted as F(x), is defined as:\n",
    "\n",
    "# F(x) = P(X ≤ x)\n",
    "\n",
    "# In words, the CDF at a particular value x tells you the probability that the random variable X is less than or equal to x.\n",
    "\n",
    "# Here's an example to illustrate the concept of a CDF:\n",
    "\n",
    "# Example:\n",
    "# Let's consider a discrete random variable X representing the outcome of rolling a fair six-sided die. The PMF for X, as described in a previous response, is as follows:\n",
    "\n",
    "# P(X = 1) = 1/6\n",
    "# P(X = 2) = 1/6\n",
    "# P(X = 3) = 1/6\n",
    "# P(X = 4) = 1/6\n",
    "# P(X = 5) = 1/6\n",
    "# P(X = 6) = 1/6\n",
    "\n",
    "# To find the CDF for X, we calculate the cumulative probabilities:\n",
    "\n",
    "# F(1) = P(X ≤ 1) = P(X = 1) = 1/6\n",
    "# F(2) = P(X ≤ 2) = P(X = 1 or X = 2) = (1/6) + (1/6) = 2/6\n",
    "# F(3) = P(X ≤ 3) = P(X = 1 or X = 2 or X = 3) = (1/6) + (1/6) + (1/6) = 3/6\n",
    "# F(4) = P(X ≤ 4) = P(X = 1 or X = 2 or X = 3 or X = 4) = (1/6) + (1/6) + (1/6) + (1/6) = 4/6\n",
    "# F(5) = P(X ≤ 5) = P(X = 1 or X = 2 or X = 3 or X = 4 or X = 5) = (1/6) + (1/6) + (1/6) + (1/6) + (1/6) = 5/6\n",
    "# F(6) = P(X ≤ 6) = P(X = 1 or X = 2 or X = 3 or X = 4 or X = 5 or X = 6) = (1/6) + (1/6) + (1/6) + (1/6) + (1/6) + (1/6) = 6/6 = 1\n",
    "\n",
    "# So, the CDF for this discrete random variable X is:\n",
    "\n",
    "# F(1) = 1/6\n",
    "# F(2) = 2/6\n",
    "# F(3) = 3/6\n",
    "# F(4) = 4/6\n",
    "# F(5) = 5/6\n",
    "# F(6) = 1\n",
    "\n",
    "# Why CDF is used:\n",
    "# The CDF is useful for several reasons:\n",
    "\n",
    "# It provides a complete summary of the probability distribution of a random variable, showing how likely it is to take on various values.\n",
    "\n",
    "# It allows you to calculate probabilities for specific events, such as finding the probability that a random variable falls within a certain range.\n",
    "\n",
    "# It is often used to compute percentiles, quartiles, and other measures that help describe the spread and central tendency of a random variable.\n",
    "\n",
    "# The CDF is essential for various statistical calculations, including hypothesis testing and confidence interval estimation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1a364",
   "metadata": {},
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal distribution, also known as the Gaussian distribution or bell curve, is a fundamental probability distribution used to model a wide range of real-world phenomena. It is characterized by its symmetric, bell-shaped curve and is fully described by two parameters: the mean (μ) and the standard deviation (σ). Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "# Height of Individuals: The heights of individuals in a population often follow a normal distribution. The mean height represents the average height of the population, while the standard deviation measures the spread or variability in heights.\n",
    "\n",
    "# Exam Scores: When a large number of students take an exam, the distribution of their scores often approximates a normal distribution. The mean score represents the average performance, and the standard deviation indicates how scores are spread around the mean.\n",
    "\n",
    "# Measurement Errors: Errors in measurements, such as errors in manufacturing or laboratory measurements, can often be modeled using a normal distribution. The mean represents the expected value of the error, and the standard deviation characterizes the variability or precision of the measurements.\n",
    "\n",
    "# IQ Scores: IQ (intelligence quotient) scores in a population tend to follow a normal distribution. The mean IQ score is typically set at 100, and the standard deviation is used to measure the variability of IQ scores within the population.\n",
    "\n",
    "# Residuals in Regression Analysis: In linear regression analysis, the residuals (the differences between observed and predicted values) are often assumed to be normally distributed with a mean of zero and a constant standard deviation. This assumption helps in making statistical inferences about the regression model.\n",
    "\n",
    "# Natural Phenomena: Some natural phenomena, like the distribution of rainfall, wind speeds, or errors in physical measurements, can be well approximated by the normal distribution.\n",
    "\n",
    "# Parameters of the Normal Distribution:\n",
    "# The normal distribution is fully characterized by two parameters:\n",
    "\n",
    "# Mean (μ): The mean of the normal distribution represents the center or average value of the data. It determines the location of the peak (the highest point) of the bell curve. Shifting the mean to the left or right moves the entire distribution along the horizontal axis.\n",
    "\n",
    "# Standard Deviation (σ): The standard deviation of the normal distribution measures the spread or variability of the data. A smaller standard deviation results in a narrower, more concentrated curve, while a larger standard deviation leads to a wider, more dispersed curve. The standard deviation controls the width of the bell curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea1be9",
   "metadata": {},
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465dd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal distribution, also known as the Gaussian distribution or bell curve, is of great importance in statistics and data analysis for several reasons:\n",
    "\n",
    "# Commonality in Nature: Many real-world phenomena naturally follow a normal distribution. This distribution often emerges due to the central limit theorem, which states that the sum or average of a large number of independent, identically distributed random variables tends to have a normal distribution. This makes the normal distribution a valuable model for understanding and analyzing a wide range of natural processes.\n",
    "\n",
    "# Statistical Inference: The normal distribution plays a central role in statistical inference. Many statistical methods, such as hypothesis testing, confidence intervals, and regression analysis, are based on assumptions of normality. When data are approximately normally distributed, these methods tend to work well and provide accurate results.\n",
    "\n",
    "# Parameter Estimation: In many statistical models, the normal distribution is used as an underlying assumption, and its parameters (mean and standard deviation) are estimated from the data. These estimates are crucial for making predictions and drawing conclusions from the data.\n",
    "\n",
    "# Predictive Modeling: In fields like finance, economics, and risk analysis, the normal distribution is often used to model uncertainties and make predictions. For example, stock price changes, interest rates, and portfolio returns are often assumed to be normally distributed to estimate risks and returns accurately.\n",
    "\n",
    "# Here are a few real-life examples of situations where the normal distribution is commonly observed:\n",
    "\n",
    "# Human Heights: The heights of individuals in a population tend to follow a normal distribution. The mean height represents the average height of the population, while the standard deviation indicates the variation in heights.\n",
    "\n",
    "# IQ Scores: IQ scores in a large population are often assumed to be normally distributed, with a mean IQ of 100 and a standard deviation of 15. This assumption helps in understanding intelligence levels in a population.\n",
    "\n",
    "# Exam Scores: In educational settings, the distribution of exam scores for a large number of students often approximates a normal distribution. This allows educators to set grading criteria and make inferences about student performance.\n",
    "\n",
    "# Measurement Errors: In scientific experiments or industrial processes, measurement errors are often normally distributed. Understanding the distribution of errors is crucial for quality control and process improvement.\n",
    "\n",
    "# Environmental Data: Variables like temperature, rainfall, and air pollution levels in certain regions can be approximately modeled using a normal distribution. This aids in weather forecasting and environmental studies.\n",
    "\n",
    "# Financial Markets: Daily returns of stocks, indices, and other financial assets are often assumed to follow a normal distribution, or a closely related distribution like the log-normal distribution, in financial modeling and risk management.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0408d",
   "metadata": {},
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049514b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The Bernoulli distribution is a probability distribution that models a random experiment with two possible outcomes: success and failure. It is named after the Swiss mathematician Jacob Bernoulli. The distribution is characterized by a single parameter, often denoted as p, which represents the probability of success. The probability of failure (not success) is then given by q = 1 - p.\n",
    "\n",
    "# Mathematically, the probability mass function (PMF) of the Bernoulli distribution is as follows:\n",
    "\n",
    "# P(X = 1) = p (for success)\n",
    "# P(X = 0) = q = 1 - p (for failure)\n",
    "\n",
    "# Here's an example to illustrate the Bernoulli distribution:\n",
    "\n",
    "# Example:\n",
    "# Consider a single flip of a fair coin, where getting heads is considered a success (1), and getting tails is considered a failure (0). The probability of getting heads (success) is p = 0.5, and the probability of getting tails (failure) is q = 1 - 0.5 = 0.5.\n",
    "\n",
    "# So, in this case, the Bernoulli distribution for this coin flip can be described as follows:\n",
    "\n",
    "# P(X = 1) = 0.5 (probability of getting heads)\n",
    "# P(X = 0) = 0.5 (probability of getting tails)\n",
    "\n",
    "# Now, let's discuss the difference between the Bernoulli distribution and the Binomial distribution:\n",
    "\n",
    "# Number of Trials:\n",
    "\n",
    "# Bernoulli Distribution: It models a single trial or experiment with two possible outcomes (success or failure).\n",
    "# Binomial Distribution: It models the number of successes (usually denoted as k) in a fixed number of independent Bernoulli trials (n trials).\n",
    "# Parameters:\n",
    "\n",
    "# Bernoulli Distribution: It has one parameter, p, which represents the probability of success in a single trial.\n",
    "# Binomial Distribution: It has two parameters, n (the number of trials) and p (the probability of success in each trial).\n",
    "# Random Variable:\n",
    "\n",
    "# Bernoulli Distribution: It deals with a single binary random variable, often denoted as X, where X can take values 0 (failure) or 1 (success).\n",
    "# Binomial Distribution: It deals with the number of successes (k) in a fixed number of trials, and the random variable represents k.\n",
    "# Probability Function:\n",
    "\n",
    "# Bernoulli Distribution: It has a simple PMF with only two possible values, 1 (for success) and 0 (for failure).\n",
    "# Binomial Distribution: It has a more complex PMF that describes the probability of getting k successes in n trials, and it involves binomial coefficients.\n",
    "# Use Cases:\n",
    "\n",
    "# Bernoulli Distribution: It is used when you are interested in modeling a single trial with two possible outcomes, such as coin flips, success/failure experiments, or binary events.\n",
    "# Binomial Distribution: It is used when you want to model the number of successes in a fixed number of independent Bernoulli trials, like the number of heads in multiple coin flips, the number of defective items in a sample, or the number of successful email responses out of a fixed number of emails sent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a99ec",
   "metadata": {},
   "source": [
    "#  question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899053e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, you can use the standard normal distribution (z-score) and then find the corresponding probability using a z-table or a calculator.\n",
    "\n",
    "# The z-score for a given value x in a normally distributed dataset with mean (μ) and standard deviation (σ) can be calculated using the formula:\n",
    "\n",
    "# ​\n",
    " \n",
    "\n",
    "# In this case:\n",
    "\n",
    "# μ (mean) = 50\n",
    "# σ (standard deviation) = 10\n",
    "# x (the value we want to find the probability for) = 60\n",
    "# So, first, calculate the z-score:\n",
    "\n",
    "# Now, you need to find the probability that a z-score is greater than 1. You can use a z-table or a calculator to find this probability. The probability corresponds to the area to the right of the z-score of 1 on the standard normal distribution curve.\n",
    "\n",
    "# Using a standard normal distribution table or calculator, you can find that the probability of a z-score greater than 1 is approximately 0.1587 (rounded to four decimal places).\n",
    "\n",
    "# So, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587, or 15.87%.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc095e0",
   "metadata": {},
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f3c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The uniform distribution is a probability distribution that describes a continuous random variable where all values within a specified range are equally likely to occur. In other words, in a uniform distribution, each possible outcome has the same probability of occurring. The uniform distribution is characterized by two parameters: the minimum value (a) and the maximum value (b), which define the range of possible outcomes.\n",
    "\n",
    "# Mathematically, the probability density function (PDF) of the uniform distribution is defined as:\n",
    "\n",
    "# f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "# f(x) = 0 otherwise\n",
    "\n",
    "# Here's an example to illustrate the uniform distribution:\n",
    "\n",
    "# Example:\n",
    "# Consider a simple example of rolling a fair six-sided die. In this case, the random variable X represents the outcome of the roll, and it can take values from 1 to 6. The uniform distribution can be used to model this situation because each of the six outcomes (1, 2, 3, 4, 5, and 6) has an equal probability of occurring.\n",
    "\n",
    "# In this example:\n",
    "\n",
    "# a (minimum value) = 1 (the lowest possible outcome)\n",
    "# b (maximum value) = 6 (the highest possible outcome)\n",
    "# Using the formula for the PDF of the uniform distribution, we can calculate the probability density function for this die roll:\n",
    "\n",
    "# f(x) = 1 / (6 - 1) = 1/5 for 1 ≤ x ≤ 6\n",
    "# f(x) = 0 otherwise\n",
    "\n",
    "# This means that for each possible outcome (1, 2, 3, 4, 5, and 6), the probability of rolling that specific number is 1/5, and the probability of rolling any other number is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fffac",
   "metadata": {},
   "source": [
    "# question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b09644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The z-score, also known as the standard score or standardized score, is a statistical measure that quantifies the number of standard deviations a data point is from the mean (average) of a dataset. It is a dimensionless number that helps in assessing how far a particular data point is from the mean in terms of the distribution's variability.\n",
    "\n",
    "# Mathematically, the z-score of an individual data point x, in a dataset with a mean (μ) and a standard deviation (σ), is calculated using the following formula:\n",
    "\n",
    " \n",
    "\n",
    "# The importance of the z-score lies in several key aspects of statistical analysis:\n",
    "\n",
    "# Normalization and Standardization: The z-score allows for the standardization of data. By calculating the z-score for each data point in a dataset, you transform the data into a common scale with a mean of 0 and a standard deviation of 1. This standardization is particularly useful when comparing data from different populations or datasets with different units or scales.\n",
    "\n",
    "# Outlier Detection: Z-scores help identify outliers or extreme values in a dataset. Data points with z-scores significantly greater than or less than zero are considered outliers and may warrant further investigation. Outliers can be indications of errors or interesting phenomena in the data.\n",
    "\n",
    "# Probability and Percentiles: Z-scores are used to calculate probabilities and determine percentiles in a standard normal distribution (a normal distribution with a mean of 0 and a standard deviation of 1). By finding the z-score corresponding to a particular value, you can determine the probability of observing a value less than or greater than that value in a normal distribution.\n",
    "\n",
    "# Hypothesis Testing: In hypothesis testing, z-scores are used to calculate test statistics for sample means, enabling researchers to make inferences about population parameters. For example, in a hypothesis test for the population mean, you calculate the z-score for a sample mean and use it to assess the evidence against the null hypothesis.\n",
    "\n",
    "# Quality Control: In manufacturing and quality control processes, z-scores can be used to monitor and control product quality. Deviations from expected z-scores can indicate variations or defects in the production process.\n",
    "\n",
    "# Data Analysis and Visualization: Z-scores can be used to standardize data for easier visualization and analysis. They can help compare data points from different sources or variables on a common scale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff04f4b",
   "metadata": {},
   "source": [
    "# question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e33652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of sample means (or other sample statistics) when drawing multiple random samples from a population, especially when the sample size is sufficiently large. It is one of the most important theorems in statistics and has far-reaching implications in various fields. The key idea behind the Central Limit Theorem is as follows:\n",
    "\n",
    "# Central Limit Theorem Statement:\n",
    "# For a sufficiently large number of random samples, the distribution of the sample means (or other sample statistics) will approximate a normal distribution, regardless of the shape of the original population distribution. The mean of the sample means will be approximately equal to the population mean, and the standard deviation of the sample means (standard error) will be approximately equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "# In mathematical terms, if X₁, X₂, ..., Xn are independent and identically distributed random variables from any population with a mean (μ) and a finite standard deviation (σ), and if n is sufficiently large, then the distribution of the sample mean (X̄) approaches a normal distribution with mean μ and standard deviation σ/√n.\n",
    "\n",
    "# Significance of the Central Limit Theorem:\n",
    "\n",
    "# Approximation to Normality: The Central Limit Theorem is significant because it allows us to work with the normal distribution, which is well-understood and for which many statistical methods have been developed. This is particularly useful because real-world data often does not follow a normal distribution, but the sample means tend to do so, especially with larger sample sizes.\n",
    "\n",
    "# Statistical Inference: The CLT forms the basis for many statistical inference procedures, such as hypothesis testing, confidence interval estimation, and regression analysis. It allows us to make inferences about population parameters based on sample statistics, assuming that the sample means follow a normal distribution.\n",
    "\n",
    "# Sample Size Determination: The CLT helps in determining the appropriate sample size for statistical studies. By knowing how sample size affects the distribution of sample means, researchers can choose an adequate sample size to meet the desired level of precision in their analysis.\n",
    "\n",
    "# Quality Control: In manufacturing and quality control processes, the CLT is used to assess the quality of products by examining the distribution of sample statistics. Deviations from expected distributions can signal quality issues.\n",
    "\n",
    "# Real-World Applications: The CLT is applied in fields such as finance, economics, epidemiology, and social sciences, where the behavior of sample means and the normal distribution assumption are commonly used in modeling and analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7fd10",
   "metadata": {},
   "source": [
    "# question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Central Limit Theorem (CLT) is a fundamental concept in statistics, but it relies on certain assumptions to hold true. These assumptions are crucial for the validity of the CLT's conclusions. Here are the key assumptions of the Central Limit Theorem:\n",
    "\n",
    "# Random Sampling: The samples must be selected randomly from the population of interest. This means that every individual or element in the population has an equal chance of being included in the sample. Non-random sampling methods can introduce bias and invalidate the CLT.\n",
    "\n",
    "# Independence: The individual observations within each sample and between different samples must be independent of each other. Independence means that the value of one observation does not depend on or influence the value of another observation. This assumption is essential for the CLT to apply.\n",
    "\n",
    "# Finite Population or Large Sample: The CLT assumes either a finite population or that the sample size is sufficiently large. In practice, there is no strict rule for what constitutes a \"sufficiently large\" sample size, but a common guideline is that the sample size should be greater than or equal to 30. When dealing with finite populations (rather than infinite populations), a finite population correction factor may be applied for small sample sizes relative to the population size.\n",
    "\n",
    "# Finite Variance: The population from which the samples are drawn must have a finite variance (finite second moment). In mathematical terms, this means that the population standard deviation (σ) should exist and be a finite, positive value. If the population variance is infinite, the CLT may not hold.\n",
    "\n",
    "# Similarity in Sample Sizes (if comparing sample means): When comparing the means of different samples (e.g., when conducting hypothesis tests or constructing confidence intervals), it is assumed that the sample sizes are approximately equal. Significant differences in sample sizes can affect the accuracy of statistical inferences.\n",
    "\n",
    "# No Extreme Skewness or Outliers: While the CLT is robust to many types of population distributions, extremely skewed distributions or the presence of outliers can impact the validity of the theorem. In such cases, larger sample sizes may be needed to ensure that the sample means approximate a normal distribution.\n",
    "\n",
    "# It's important to note that the Central Limit Theorem is an asymptotic result, meaning that it becomes increasingly accurate as the sample size grows larger. For practical purposes, the CLT is often considered applicable when the sample size is reasonably large, even if some of the assumptions are only approximately met.\n",
    "\n",
    "# Violations of these assumptions can lead to inaccurate results or erroneous conclusions, so it's essential to consider the context of your data and ensure that the assumptions are reasonably satisfied when applying the CLT in statistical analyses.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
